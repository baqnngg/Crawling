from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
import time
import pandas as pd

def crawl_naver_map(url, fields, scroll_count=7, driver_path=None, excel_filename="output.xlsx"):
    options = webdriver.ChromeOptions()
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument("--start-maximized")

    service = Service(driver_path)
    driver = webdriver.Chrome(service=service, options=options)
    driver.get(url)
    time.sleep(3)

    # ê²€ìƒ‰ ê²°ê³¼ iframe ì§„ì…
    driver.switch_to.frame("searchIframe")
    time.sleep(2)

    data_list = []

    while True:
        scroll_container = driver.find_element(By.ID, "_pcmap_list_scroll_container")

        # í˜„ì¬ í˜ì´ì§€ ìŠ¤í¬ë¡¤ ë‹¤ìš´
        for _ in range(scroll_count):
            driver.execute_script("arguments[0].scrollTop += 1000;", scroll_container)
            time.sleep(1.2)

        # ì•„ì´í…œ ìˆ˜ì§‘
        items = driver.find_elements(By.CSS_SELECTOR, "li.UEzoS.rTjJo")

        for item in items:
            data = {}
            for col_name, (selector, method) in fields.items():
                try:
                    if method == "css":
                        elements = item.find_elements(By.CSS_SELECTOR, selector)
                    elif method == "xpath":
                        elements = item.find_elements(By.XPATH, selector)
                    else:
                        elements = []

                    text = elements[0].text.strip() if elements else f"{col_name} ì—†ìŒ"
                    data[col_name] = text

                except Exception as e:
                    data[col_name] = f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            data_list.append(data)

        # ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ ì°¾ê¸°
        try:
            next_button = driver.find_element(
                By.XPATH,
                '//a[contains(@class, "eUTV2") and .//span[text()="ë‹¤ìŒí˜ì´ì§€"] and @aria-disabled="false"]'
            )
            driver.execute_script("arguments[0].click();", next_button)
            time.sleep(3)
        except:
            print("ğŸ”š ë‹¤ìŒ í˜ì´ì§€ ì—†ìŒ ë˜ëŠ” ì´ë™ ë¶ˆê°€ â†’ ì¢…ë£Œ")
            break


    driver.quit()

    df = pd.DataFrame(data_list)
    df.to_excel(excel_filename, index=False)
    print(f"âœ… ì €ì¥ ì™„ë£Œ - {excel_filename}")


if __name__ == "__main__":
    driver_path = "C:\\Users\\il869\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe"
    url = "https://map.naver.com/p/search/ì¶©ì£¼ìŒì‹ì "

    fields = {
        "ì´ë¦„": ("span.TYaxT", "css"),
        "ì¹´í…Œê³ ë¦¬": ("span.KCMnt", "css"),
        "ì„¤ëª…": ("a.nyHXH", "css"),
        "ë³„ì ": ("span.orXYY", "css"),
        "ë¦¬ë·° ìˆ˜": (".//span[contains(text(), 'ë¦¬ë·°')]", "xpath")
    }

    crawl_naver_map(url, fields, scroll_count=25, driver_path=driver_path, excel_filename="ì¶©ì£¼ìŒì‹ì .xlsx")