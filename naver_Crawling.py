from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
import pandas as pd

def crawl_naver_map(url, fields, scroll_count=7, driver_path=None, excel_filename="output.xlsx"):
    options = webdriver.ChromeOptions()
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument("--start-maximized")

    service = Service(driver_path)
    driver = webdriver.Chrome(service=service, options=options)
    driver.get(url)
    time.sleep(3)

    # ê²€ìƒ‰ ê²°ê³¼ iframe ì§„ì…
    WebDriverWait(driver, 10).until(EC.frame_to_be_available_and_switch_to_it((By.ID, "searchIframe")))
    time.sleep(2)

    data_list = []

    while True:
        scroll_container = driver.find_element(By.ID, "_pcmap_list_scroll_container")

        # í˜„ì¬ í˜ì´ì§€ ìŠ¤í¬ë¡¤ ë‹¤ìš´
        for _ in range(scroll_count):
            driver.execute_script("arguments[0].scrollTop += 1000;", scroll_container)
            time.sleep(1.2)

        # ì•„ì´í…œ ìˆ˜ì§‘
        items = driver.find_elements(By.CSS_SELECTOR, "li.UEzoS.rTjJo")

        for item in items:
            data = {}

            # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            for col_name, (selector, method) in fields.items():
                try:
                    if method == "css":
                        elements = item.find_elements(By.CSS_SELECTOR, selector)
                    elif method == "xpath":
                        elements = item.find_elements(By.XPATH, selector)
                    else:
                        elements = []

                    text = elements[0].text.strip() if elements else f"{col_name} ì—†ìŒ"
                    data[col_name] = text

                except Exception as e:
                    data[col_name] = f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

            # âœ… ì£¼ì†Œ ìˆ˜ì§‘
            try:
                # ìì„¸íˆ ë³´ê¸° í´ë¦­
                detail_button = item.find_element(By.CSS_SELECTOR, "a.place_bluelink.N_KDL.CtW3e")
                driver.execute_script("arguments[0].click();", detail_button)
                time.sleep(1)

                # entryIframe ì „í™˜
                driver.switch_to.default_content()
                WebDriverWait(driver, 10).until(EC.frame_to_be_available_and_switch_to_it((By.ID, "entryIframe")))
                time.sleep(0.5)

                # ì£¼ì†Œ ì¶”ì¶œ
                address_element = WebDriverWait(driver, 5).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, "span.LDgIH"))
                )
                address = address_element.text.strip()
                print(address)
            except Exception as e:
                address = f"ì£¼ì†Œ ì˜¤ë¥˜: {str(e)}"

            # ë‹¤ì‹œ ê²€ìƒ‰ í”„ë ˆì„ìœ¼ë¡œ ì „í™˜
            driver.switch_to.default_content()
            WebDriverWait(driver, 10).until(EC.frame_to_be_available_and_switch_to_it((By.ID, "searchIframe")))
            time.sleep(0.5)

            data["ì£¼ì†Œ"] = address
            data_list.append(data)

        # ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ í´ë¦­ ì‹œë„
        try:
            next_button = driver.find_element(
                By.XPATH,
                '//a[contains(@class, "eUTV2") and .//span[text()="ë‹¤ìŒí˜ì´ì§€"] and @aria-disabled="false"]'
            )
            driver.execute_script("arguments[0].click();", next_button)
            time.sleep(3)
        except:
            print("ğŸ”š ë‹¤ìŒ í˜ì´ì§€ ì—†ìŒ ë˜ëŠ” ì´ë™ ë¶ˆê°€ â†’ ì¢…ë£Œ")
            break

    driver.quit()

    df = pd.DataFrame(data_list)
    df.to_excel(excel_filename, index=False)
    print(f"âœ… ì €ì¥ ì™„ë£Œ - {excel_filename}")

if __name__ == "__main__":
    driver_path = "C:\\Users\\User\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe"
    url = "https://map.naver.com/p/search/ì¶©ì£¼ìŒì‹ì "

    fields = {
        "ì´ë¦„": ("span.TYaxT", "css"),
        "ì¹´í…Œê³ ë¦¬": ("span.KCMnt", "css"),
        "ì„¤ëª…": ("a.nyHXH", "css"),
        "ë³„ì ": ("span.orXYY", "css"),
        "ë¦¬ë·° ìˆ˜": (".//span[contains(text(), 'ë¦¬ë·°')]", "xpath")
    }

    crawl_naver_map(url, fields, scroll_count=25, driver_path=driver_path, excel_filename="ì¶©ì£¼ìŒì‹ì _ë„¤ì´ë²„.xlsx")