from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
import pandas as pd
import requests

def get_coordinates_to_excel(query, search_coord):
    base_url = "https://map.naver.com/v5/api/search/allSearch"
    
    params = {
        'query': query,
        'type': 'all',
        'searchCoord': search_coord,
        'boundary': ''
    }
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36',
        'Referer': 'https://map.naver.com/',
        'Accept': 'application/json, text/plain, */*',
    }
    
    response = requests.get(base_url, params=params, headers=headers)
    
    try:
        data = response.json()
    except Exception as e:
        print("JSON parsing error:", e)
        return
    
    places = data.get('result', {}).get('place', {}).get('list', [])
    
    # ë¦¬ìŠ¤íŠ¸ë¥¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    rows = []
    for place in places:
        name = place.get('name')
        x = place.get('x')
        y = place.get('y')
        rows.append({'xì¢Œí‘œ': x, 'yì¢Œí‘œ': y})
    return rows

def crawl_naver_map(url, fields, scroll_count=7, driver_path=None, excel_filename="output.xlsx"):
    options = webdriver.ChromeOptions()
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument("--start-maximized")

    service = Service(driver_path)
    driver = webdriver.Chrome(service=service, options=options)
    driver.get(url)
    time.sleep(3)

    # ê²€ìƒ‰ ê²°ê³¼ iframe ì§„ì…
    WebDriverWait(driver, 10).until(EC.frame_to_be_available_and_switch_to_it((By.ID, "searchIframe")))
    time.sleep(2)

    data_list = []

    while True:
        scroll_container = driver.find_element(By.ID, "_pcmap_list_scroll_container")

        # í˜„ì¬ í˜ì´ì§€ ìŠ¤í¬ë¡¤ ë‹¤ìš´
        for _ in range(scroll_count):
            driver.execute_script("arguments[0].scrollTop += 1000;", scroll_container)
            time.sleep(1.2)

        # ì•„ì´í…œ ìˆ˜ì§‘
        items = driver.find_elements(By.CSS_SELECTOR, "li.UEzoS.rTjJo")

        for item in items:
            data = {}

            # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            for col_name, (selector, method) in fields.items():
                try:
                    if method == "css":
                        elements = item.find_elements(By.CSS_SELECTOR, selector)
                    elif method == "xpath":
                        elements = item.find_elements(By.XPATH, selector)
                    else:
                        elements = []

                    text = elements[0].text.strip() if elements else f"{col_name} ì—†ìŒ"
                    data[col_name] = text

                except Exception as e:
                    data[col_name] = f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

            # âœ… ì£¼ì†Œ ìˆ˜ì§‘
            try:
                # ìì„¸íˆ ë³´ê¸° í´ë¦­
                detail_button = item.find_element(By.CSS_SELECTOR, "a.place_bluelink.N_KDL.CtW3e")
                driver.execute_script("arguments[0].click();", detail_button)
                time.sleep(1)

                # entryIframe ì „í™˜
                driver.switch_to.default_content()
                WebDriverWait(driver, 10).until(EC.frame_to_be_available_and_switch_to_it((By.ID, "entryIframe")))
                time.sleep(0.5)

                # ì£¼ì†Œ ì¶”ì¶œ
                address_element = WebDriverWait(driver, 5).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, "span.LDgIH"))
                )
                address = address_element.text.strip()
                if data["ì´ë¦„"] != None:
                    time.sleep(0.5)
                    lalo = get_coordinates_to_excel(data["ì´ë¦„"], search_coord)
                    latitude, longitude = lalo[0]['xì¢Œí‘œ'], lalo[0]['yì¢Œí‘œ']
                    data["ìœ„ë„"], data["ê²½ë„"] = latitude, longitude

                print(address)
            except Exception as e:
                address = f"ì£¼ì†Œ ì˜¤ë¥˜: {str(e)}"

            # ë‹¤ì‹œ ê²€ìƒ‰ í”„ë ˆì„ìœ¼ë¡œ ì „í™˜
            driver.switch_to.default_content()
            WebDriverWait(driver, 10).until(EC.frame_to_be_available_and_switch_to_it((By.ID, "searchIframe")))
            time.sleep(0.5)

            data["ì£¼ì†Œ"] = address
            data_list.append(data)

        # ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ í´ë¦­ ì‹œë„
        try:
            next_button = driver.find_element(
                By.XPATH,
                '//a[contains(@class, "eUTV2") and .//span[text()="ë‹¤ìŒí˜ì´ì§€"] and @aria-disabled="false"]'
            )
            driver.execute_script("arguments[0].click();", next_button)
            time.sleep(3)
        except:
            print("ğŸ”š ë‹¤ìŒ í˜ì´ì§€ ì—†ìŒ ë˜ëŠ” ì´ë™ ë¶ˆê°€ â†’ ì¢…ë£Œ")
            break

    driver.quit()

    df = pd.DataFrame(data_list)
    df.to_excel(excel_filename, index=False)
    print(f"âœ… ì €ì¥ ì™„ë£Œ - {excel_filename}")

if __name__ == "__main__":
    driver_path = "C:\\Users\\User\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe"
    url = "https://map.naver.com/p/search/ì¶©ì£¼ìŒì‹ì "

    search_coord = "127.93883339999621;36.96102790000016"

    fields = {
        "ì´ë¦„": ("span.TYaxT", "css"),
        "ì¹´í…Œê³ ë¦¬": ("span.KCMnt", "css"),
        "ì„¤ëª…": ("a.nyHXH", "css"),
        "ë³„ì ": ("span.orXYY", "css"),
        "ë¦¬ë·° ìˆ˜": (".//span[contains(text(), 'ë¦¬ë·°')]", "xpath")
    }

    crawl_naver_map(url, fields, scroll_count=25, driver_path=driver_path, excel_filename="ì¶©ì£¼ìŒì‹ì _ë„¤ì´ë²„_ìœ„ë„ê²½ë„.xlsx")